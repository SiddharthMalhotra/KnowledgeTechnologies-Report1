\begin{abstract}
In this report, we discuss two major spelling correction methodologies on the problem of tweet normalisation specifically on Twitter data. Firstly, discuss the combination of Levenshtein Distance, Peter Norwig Algorithm and n-gram context matching, namely LRPN approach. The second method involves first preprocessing the text, tokenisation is performed through NLTK, a lexicon and confusion set is built, scoring and ranking of possible interpretation of Out-of-vocabulary words (OOVs),decoding the confusion lattice thus formed using SRI-LM toolkit, namely NLTK-SRI technique. Further, we perform a critical analysis of these approaches by calculating the $precision$ and $recall$ values.

\end{abstract}
